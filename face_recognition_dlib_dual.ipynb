{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition_dlib_dual.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoEBPCqKZ5WfmPeOiEXn+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishkr108/Learning-Path/blob/main/face_recognition_dlib_dual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTYmiKkFMo9p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dlib\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import cv2\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.path.expanduser('~/data')\n",
        "faces_folder_path = data_dir + '/kodemaker/'"
      ],
      "metadata": {
        "id": "_S6-B-BTNCUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Globals\n",
        "face_detector_dlib = dlib.get_frontal_face_detector()\n",
        "shape_predictor = dlib.shape_predictor(data_dir + '/dlib/shape_predictor_5_face_landmarks.dat')\n",
        "face_recognition_model = dlib.face_recognition_model_v1(data_dir + '/dlib/dlib_face_recognition_resnet_model_v1.dat')\n",
        "face_classifier_opencv = cv2.CascadeClassifier(data_dir + '/opencv/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "MCRj-dS7NE-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timefn(fn, args):\n",
        "    start = datetime.now()\n",
        "    r = fn(*args)\n",
        "    elapsed = datetime.now() - start\n",
        "    print(fn.__name__ + \" took \", elapsed)\n",
        "    return r\n"
      ],
      "metadata": {
        "id": "K64J_vKPNFBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dlib_rect(w, h):\n",
        "    return dlib.rectangle(left=0, top=0, right=w, bottom=h)"
      ],
      "metadata": {
        "id": "lzbJU_0WNFD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_rect(dr):\n",
        "    #  (x, y, w, h)\n",
        "    return dr.left(), dr.top(), dr.right()-dr.left(), dr.bottom()-dr.top()"
      ],
      "metadata": {
        "id": "qOT7VC-CNFH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_detector_opencv(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return face_classifier_opencv.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=5,\n",
        "        minSize=(100, 100),\n",
        "        flags=cv2.CASCADE_SCALE_IMAGE)"
      ],
      "metadata": {
        "id": "8CFoL3vxNFKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face_encodings(face, bounds):\n",
        "    # start = datetime.now()\n",
        "    # bounds = face_detector(face, 1)\n",
        "    # print(\"Dlib Getting bounds took \", (datetime.now() - start))\n",
        "    start = datetime.now()\n",
        "    faces_landmarks = [shape_predictor(face, face_bounds) for face_bounds in bounds]\n",
        "    print(\"Getting shape predictors took \", (datetime.now() - start))\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(face, face_pose, 1)) for face_pose in faces_landmarks]"
      ],
      "metadata": {
        "id": "X6KTIXwJNFZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face_matches(known_faces, face):\n",
        "    return np.linalg.norm(known_faces - face, axis=1)"
      ],
      "metadata": {
        "id": "ook5P23lNFcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_match(known_faces, person_names, face):\n",
        "    matches = get_face_matches(known_faces, face) # get a list of True/False\n",
        "    min_index = matches.argmin()\n",
        "    min_value = matches[min_index]\n",
        "    if min_value < 0.58:\n",
        "        return person_names[min_index]+\" ({0:.2f})\".format(min_value)\n",
        "    if min_value < 0.65:\n",
        "        return person_names[min_index]+\"?\"+\" ({0:.2f})\".format(min_value)\n",
        "    return 'Not Found'\n"
      ],
      "metadata": {
        "id": "B-8G2-IGNFez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_face_encodings(faces_folder_path):\n",
        "    image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir(faces_folder_path))\n",
        "    image_filenames = sorted(image_filenames)\n",
        "    person_names = [x[:-4] for x in image_filenames]\n",
        "\n",
        "    full_paths_to_images = [faces_folder_path + x for x in image_filenames]\n",
        "    face_encodings = []\n",
        "\n",
        "    win = dlib.image_window()\n",
        "\n",
        "    for path_to_image in full_paths_to_images:\n",
        "        face = io.imread(path_to_image)\n",
        "\n",
        "        faces_bounds = face_detector_dlib(face, 0)\n",
        "\n",
        "        if len(faces_bounds) != 1:\n",
        "            print(\"Expected one and only one face per image: \" + path_to_image + \" - it has \" + str(len(faces_bounds)))\n",
        "            exit()\n",
        "\n",
        "        face_bounds = faces_bounds[0]\n",
        "        face_landmarks = shape_predictor(face, face_bounds)\n",
        "        face_encoding = np.array(\n",
        "            face_recognition_model.compute_face_descriptor(face, face_landmarks, 1)\n",
        "        )\n",
        "\n",
        "\n",
        "        win.clear_overlay()\n",
        "        win.set_image(face)\n",
        "        win.add_overlay(face_bounds)\n",
        "        win.add_overlay(face_landmarks)\n",
        "        face_encodings.append(face_encoding)\n",
        "\n",
        "        print(face_encoding)\n",
        "\n",
        "        # dlib.hit_enter_to_continue()\n",
        "    return face_encodings, person_names"
      ],
      "metadata": {
        "id": "OdsQPytSNFif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_faces_in_video(face_encodings, person_names):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start = datetime.now()\n",
        "        face_rects = face_detector_opencv(frame)\n",
        "        print(\"CV2 Getting bounds took \", (datetime.now() - start))\n",
        "        #start = datetime.now()\n",
        "        #bounds = face_detector(frame, 1)\n",
        "        #print(\"dlib Getting bounds took \", (datetime.now() - start))\n",
        "\n",
        "        for (x, y, w, h) in face_rects:\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "            face = frame[y:y + h, x:x + w]\n",
        "\n",
        "            bounds = ([to_dlib_rect(w.item(), h.item())])\n",
        "            face_encodings_in_image = get_face_encodings(face, bounds)\n",
        "            if (face_encodings_in_image):\n",
        "                match = find_match(face_encodings, person_names, face_encodings_in_image[0])\n",
        "                cv2.putText(frame, match, (x+5, y-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "\n",
        "            # Debugging dlib localizer:\n",
        "            bounds = face_detector_dlib(frame, 0)\n",
        "            if (bounds):\n",
        "                b = bounds[0]\n",
        "                cv2.rectangle(frame, (b.left(), b.top()), (b.right(), b.bottom()), (255, 255, 0), 2)\n",
        "            face_encodings_in_image = get_face_encodings(frame, bounds)\n",
        "            if (face_encodings_in_image):\n",
        "                match = find_match(face_encodings, person_names, face_encodings_in_image[0])\n",
        "                cv2.putText(frame, match, (b.left()+5, b.top()-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow(\"bilde\", frame)\n",
        "\n",
        "        if cv2.waitKey(10) == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Tr-V9QTNNaFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_encodings, person_names = load_face_encodings(faces_folder_path)\n",
        "recognize_faces_in_video(face_encodings, person_names)"
      ],
      "metadata": {
        "id": "vOV5hRBjNca7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}